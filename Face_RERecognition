import cv2
import os
import numpy as np
import pickle
import time
from kivy.app import App
from kivy.uix.button import Button
from kivy.uix.label import Label
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.camera import Camera
from kivy.uix.textinput import TextInput
from kivy.uix.popup import Popup
from kivy.uix.screenmanager import ScreenManager, Screen
from kivy.clock import Clock

# Define paths and setup
captured_faces_folder = 'captured_faces'
recognizer = cv2.face.LBPHFaceRecognizer_create()
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Ensure the folder for captured faces exists
if not os.path.exists(captured_faces_folder):
    os.makedirs(captured_faces_folder)

# Global variable to track the name entered for capturing faces
name_for_capture = None
capture_count = 0

class MainScreen(Screen):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Main layout with vertical orientation (so everything will be stacked vertically)
        self.layout = BoxLayout(orientation='vertical',padding=[50,50,50,50])
        
        # Info label at the top
        self.info_label = Label(text="Welcome to Face Recognition System",halign="center",valign="middle",font_size="50sp")
        
        
        # Add the info label to the layout
        self.layout.add_widget(self.info_label)

        # Horizontal layout for buttons and text input
        button_layout = BoxLayout(orientation='horizontal')
        
        # Capture button
        self.capture_button = Button(text="Capture Face", size_hint=(1, 0.1))
        self.capture_button.bind(on_press=self.on_capture_button_click)
        button_layout.add_widget(self.capture_button)

        # Train button
        self.train_button = Button(text="Train Recognizer", size_hint=(1, 0.1))
        self.train_button.bind(on_press=self.on_train_button_click)
        button_layout.add_widget(self.train_button)

        # Recognize button
        self.recognize_button = Button(text="Start Recognition", size_hint=(1, 0.1))
        self.recognize_button.bind(on_press=self.on_recognize_button_click)
        button_layout.add_widget(self.recognize_button)

        # Text input field
        self.text_input = TextInput(hint_text="Enter your name for capture", size_hint=(1, 0.1))
        button_layout.add_widget(self.text_input)

        # Add the button layout below the label
        self.layout.add_widget(button_layout)
        
        # Add the entire layout to the screen
        self.add_widget(self.layout)


    def on_capture_button_click(self, instance):
        # Go to capture screen
        name = self.text_input.text.strip()
        if name:
            self.manager.current = 'capture_screen'
            capture_screen = self.manager.get_screen('capture_screen')
            capture_screen.start_capture(name)
        else:
            self.show_popup("Error", "Please enter your name to proceed.")

    def on_train_button_click(self, instance):
        # Go to training screen
        self.manager.current = 'train_screen'
        train_screen = self.manager.get_screen('train_screen')
        train_screen.start_training()

    def on_recognize_button_click(self, instance):
        # Go to recognition screen
        self.manager.current = 'recognize_screen'
        recognize_screen = self.manager.get_screen('recognize_screen')
        recognize_screen.start_recognition()

    def show_popup(self, title, message):
        popup = Popup(title=title, content=Label(text=message), size_hint=(None, None), size=(400, 200))
        popup.open()

class CaptureScreen(Screen):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.layout = BoxLayout(orientation='vertical')

        self.camera = Camera(play=True, resolution=(640, 480))
        self.layout.add_widget(self.camera)

        self.info_label = Label(text="Capturing Faces...", size_hint=(1, 0.1))
        self.layout.add_widget(self.info_label)

        self.close_button = Button(text="Close", size_hint=(1, 0.1))
        self.close_button.bind(on_press=self.close_capture)
        self.layout.add_widget(self.close_button)

        self.add_widget(self.layout)

    def start_capture(self, name):
        self.name_for_capture = name
        self.capture_count = 0
        self.capture_face(name)

    def capture_face(self, name, capture_count=4):
        cap = cv2.VideoCapture(0)
        count = 0
        self.info_label.text = f"Capturing {capture_count} face images for {name}..."

        while count < capture_count:
            ret, frame = cap.read()
            if not ret:
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

            if len(faces) > 0:
                for (x, y, w, h) in faces:
                    roi_gray = gray[y:y + h, x:x + w]
                    cv2.imwrite(f"{captured_faces_folder}/{name}_{count}.jpg", frame)
                    count += 1
                    self.info_label.text = f"Captured {count}/{capture_count} face images."

            time.sleep(2)  # Simulate waiting for next face direction

        cap.release()
        self.info_label.text = "Capture completed. Press Close to go back."
    
    def close_capture(self, instance):
        self.manager.current = 'main_screen'

class TrainScreen(Screen):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.layout = BoxLayout(orientation='vertical')

        self.info_label = Label(text="Training Recognizer...", size_hint=(1, 0.1))
        self.layout.add_widget(self.info_label)

        self.close_button = Button(text="Close", size_hint=(1, 0.1))
        self.close_button.bind(on_press=self.close_training)
        self.layout.add_widget(self.close_button)

        self.add_widget(self.layout)

    def start_training(self):
        self.train_recognizer()

    def train_recognizer(self):
        faces = []
        labels = []
        name_to_id = {}
        current_label = 0

        for filename in os.listdir(captured_faces_folder):
            if filename.endswith('.jpg'):
                name = filename.split('_')[0]
                if name not in name_to_id:
                    name_to_id[name] = current_label
                    current_label += 1

                img = cv2.imread(f'{captured_faces_folder}/{filename}')
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                faces_detected = face_cascade.detectMultiScale(gray)

                for (x, y, w, h) in faces_detected:
                    roi_gray = gray[y:y + h, x:x + w]
                    faces.append(roi_gray)
                    labels.append(name_to_id[name])

        recognizer.train(faces, np.array(labels))
        recognizer.save('face_recognizer.yml')

        with open('name_to_id.pkl', 'wb') as f:
            pickle.dump(name_to_id, f)

        self.info_label.text = "Training completed."

    def close_training(self, instance):
        self.manager.current = 'main_screen'

class RecognizeScreen(Screen):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.layout = BoxLayout(orientation='vertical')

        self.camera = Camera(play=True, resolution=(640, 480))
        self.layout.add_widget(self.camera)

        self.info_label = Label(text="Recognizing Faces...", size_hint=(1, 0.1))
        self.layout.add_widget(self.info_label)

        self.close_button = Button(text="Close", size_hint=(1, 0.1))
        self.close_button.bind(on_press=self.close_recognition)
        self.layout.add_widget(self.close_button)

        self.add_widget(self.layout)

    def start_recognition(self):
        self.recognize_face()

    def recognize_face(self):
        cap = cv2.VideoCapture(0)
        recognizer.read('face_recognizer.yml')

        with open('name_to_id.pkl', 'rb') as f:
            name_to_id = pickle.load(f)

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(gray)

            for (x, y, w, h) in faces:
                roi_gray = gray[y:y + h, x:x + w]

                label, confidence = recognizer.predict(roi_gray)

                if confidence < 100:
                    name = list(name_to_id.keys())[list(name_to_id.values()).index(label)]
                else:
                    name = "Unknown"

                cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            cv2.imshow("Face Recognition", frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

    def close_recognition(self, instance):
        self.manager.current = 'main_screen'


class FaceRecognitionApp(App):
    def build(self):
        self.sm = ScreenManager()

        self.main_screen = MainScreen(name='main_screen')
        self.capture_screen = CaptureScreen(name='capture_screen')
        self.train_screen = TrainScreen(name='train_screen')
        self.recognize_screen = RecognizeScreen(name='recognize_screen')

        self.sm.add_widget(self.main_screen)
        self.sm.add_widget(self.capture_screen)
        self.sm.add_widget(self.train_screen)
        self.sm.add_widget(self.recognize_screen)

        return self.sm

if __name__ == '__main__':
    FaceRecognitionApp().run()
